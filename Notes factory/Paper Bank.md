If there is corresponding note link it after the paper using [[]] and pointing to the note file - the note does not need to have the same name as the paper and may be more general or specific.
## VAE
- [Semi-supervised Learning with Deep Generative Models](https://arxiv.org/pdf/1406.5298)
- ### IWAE
	- [Hierarchical Importance Weighted Autoencoders](http://proceedings.mlr.press/v97/huang19d/huang19d.pdf)
	- [On importance-weighted autoencoders](https://arxiv.org/abs/1907.10477)
	- [DEBIASING EVIDENCE APPROXIMATIONS: ON IMPORTANCE-WEIGHTED AUTOENCODERS AND JACKKNIFE VARIATIONAL INFERENCE](https://www.microsoft.com/en-us/research/uploads/prod/2018/04/On-Importance-weighted-Autoencoders-and-Jackknife-Variational-Inference.pdf)
- ### Discrete variables - continous latent
	- [Grammar Variational Autoencoder](https://arxiv.org/abs/1703.01925)
	- [Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules](https://arxiv.org/abs/1610.02415)
- ### Priors
	- [VAE with a VampPrior](https://proceedings.mlr.press/v84/tomczak18a/tomczak18a.pdf)
## Multimodal latent integration
- babel
- omivae
- aae